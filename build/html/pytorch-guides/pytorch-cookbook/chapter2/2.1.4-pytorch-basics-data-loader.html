<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>3.1.15. PyTorch 基础 :数据的加载和预处理 &mdash; AI 模型国内加速  文档</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/translations.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="author" title="关于这些文档" href="../../../about.html" />
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="3.1.16. 2.2 深度学习基础及数学原理" href="2.2-deep-learning-basic-mathematics.html" />
    <link rel="prev" title="3.1.14. PyTorch 基础 : 神经网络包nn和优化器optm" href="2.1.3-pytorch-basics-nerual-network.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            AI 模型国内加速
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../best-practice/index.html">1. 【AI网盘】人工智能资源汇总</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stable-diffusion/index.html">2. Stable Diffusion</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">3. Pytorch 教程</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">3.1. Pytorch 快速入门</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../chapter1/1.1-pytorch-introduction.html">3.1.1. 1.1 Pytorch 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/1.2-pytorch-installation.html">3.1.2. 1.2 Pytorch环境搭建</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/1.2-pytorch-installation.html#id1">3.1.3. 1.2.1 安装Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/1.3-deep-learning-with-pytorch-60-minute-blitz.html">3.1.4. PyTorch 深度学习:60分钟快速入门 （官方）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/1.4-pytorch-resource.html">3.1.5. 相关资源列表</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/1_tensor_tutorial.html">3.1.6. PyTorch是什么?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/2_autograd_tutorial.html">3.1.7. Autograd: 自动求导机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/3_neural_networks_tutorial.html">3.1.8. Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/4_cifar10_tutorial.html">3.1.9. 训练一个分类器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/5_data_parallel_tutorial.html">3.1.10. 数据并行（选读）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter1/readme.html">3.1.11. PyTorch 中文手册第一章 ： PyTorch入门</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.1.1.pytorch-basics-tensor.html">3.1.12. PyTorch 基础 : 张量</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.1.2-pytorch-basics-autograd.html">3.1.13. 使用PyTorch计算梯度数值</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.1.3-pytorch-basics-nerual-network.html">3.1.14. PyTorch 基础 : 神经网络包nn和优化器optm</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">3.1.15. PyTorch 基础 :数据的加载和预处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dataset">3.1.15.1. Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataloader">3.1.15.2. Dataloader</a></li>
<li class="toctree-l4"><a class="reference internal" href="#torchvision">3.1.15.3. torchvision 包</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2.2-deep-learning-basic-mathematics.html">3.1.16. 2.2 深度学习基础及数学原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.3-deep-learning-neural-network-introduction.html">3.1.17. 2.3 神经网络简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.4-cnn.html">3.1.18. 2.4 卷积神经网络简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.5-rnn.html">3.1.19. 2.5 循环神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="readme.html">3.1.20. Pytorch 中文手册第二章 ： 基础</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/3.1-logistic-regression.html">3.1.21. 3.1 logistic回归实战</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/3.2-mnist.html">3.1.22. 3.2  MNIST数据集手写数字识别</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/3.3-rnn.html">3.1.23. 3.3 通过Sin预测Cos</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/readme.html">3.1.24. Pytorch 中文手册第三章 ： 实践</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.1-fine-tuning.html">3.1.25. 4.1 Fine tuning 模型微调</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.2.1-visdom.html">3.1.26. 4.2.1 使用Visdom在 PyTorch 中进行可视化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.2.2-tensorboardx.html">3.1.27. 4.2.2 使用Tensorboard在 PyTorch 中进行可视化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.2.3-cnn-visualizing.html">3.1.28. 4.2.3 可视化理解卷积神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.2.3-cnn-visualizing.html#backpropagation">3.1.29. 基于Backpropagation的方法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.3-fastai.html">3.1.30. 4.3 fastai</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/4.5-multiply-gpu-parallel-training.html">3.1.31. 4.5 多GPU并行训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/distributed_data_parallel.html">3.1.32. 在PyTorch中使用DistributedDataParallel进行多GPU分布式模型训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/readme.html">3.1.33. Pytorch 中文手册第四章 ： 提高</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter5/5.1-kaggle.html">3.1.34. 5.1 kaggle介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter5/5.2-Structured-Data.html">3.1.35. 5.2 Pytorch处理结构化数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter5/5.3-Fashion-MNIST.html">3.1.36. Fashion MNIST进行分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../chapter5/readme.html">3.1.37. Pytorch 中文手册第五章 ： 应用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../style-guides/index.html">4. 编程语言 风格指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../coding/index.html">5. 编程语言 语法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cheatsheet/index.html">6. Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about.html">7. 关于</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">AI 模型国内加速</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html"><span class="section-number">3. </span>Pytorch 教程</a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">3.1. </span>Pytorch 快速入门</a></li>
      <li class="breadcrumb-item active"><span class="section-number">3.1.15. </span>PyTorch 基础 :数据的加载和预处理</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/pytorch-guides/pytorch-cookbook/chapter2/2.1.4-pytorch-basics-data-loader.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pytorch">
<h1><span class="section-number">3.1.15. </span>PyTorch 基础 :数据的加载和预处理<a class="headerlink" href="#pytorch" title="Permalink to this heading"></a></h1>
<p>PyTorch通过torch.utils.data对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。
并且torchvision已经预先实现了常用图像数据集，包括前面使用过的CIFAR-10，ImageNet、COCO、MNIST、LSUN等数据集，可通过torchvision.datasets方便的调用</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 首先要引入相关的包</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="c1">#打印一下版本</span>
<span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;1.0.1.post2&#39;</span>
</pre></div>
</div>
<section id="dataset">
<h2><span class="section-number">3.1.15.1. </span>Dataset<a class="headerlink" href="#dataset" title="Permalink to this heading"></a></h2>
<p>Dataset是一个抽象类，为了能够方便的读取，需要将要使用的数据包装为Dataset类。
自定义的Dataset需要继承它并且实现两个成员方法：</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__getitem__()</span></code> 该方法定义用索引(<code class="docutils literal notranslate"><span class="pre">0</span></code> 到 <code class="docutils literal notranslate"><span class="pre">len(self)</span></code>)获取一条数据或一个样本</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__len__()</span></code> 该方法返回数据集的总长度</p></li>
</ol>
<p>下面我们使用kaggle上的一个竞赛<a class="reference external" href="https://www.kaggle.com/c/bluebook-for-bulldozers/data">bluebook for bulldozers</a>自定义一个数据集，为了方便介绍，我们使用里面的数据字典来做说明（因为条数少）</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#引用</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#定义一个数据集</span>
<span class="k">class</span> <span class="nc">BulldozerDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; 数据集演示 &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">csv_file</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;实现初始化方法，在初始化的时候将数据读载入&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        返回df的长度</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        根据 idx 返回一行数据</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
<p>至此，我们的数据集已经定义完成了，我们可以实例化一个对象访问它</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds_demo</span><span class="o">=</span> <span class="n">BulldozerDataset</span><span class="p">(</span><span class="s1">&#39;median_benchmark.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>我们可以直接使用如下命令查看数据集数据</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#实现了 __len__ 方法所以可以直接使用len获取数据总数</span>
<span class="nb">len</span><span class="p">(</span><span class="n">ds_demo</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">11573</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#用索引可以直接访问对应的数据，对应 __getitem__ 方法</span>
<span class="n">ds_demo</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">24000.0</span>
</pre></div>
</div>
<p>自定义的数据集已经创建好了，下面我们使用官方提供的数据载入器，读取数据</p>
</section>
<section id="dataloader">
<h2><span class="section-number">3.1.15.2. </span>Dataloader<a class="headerlink" href="#dataloader" title="Permalink to this heading"></a></h2>
<p>DataLoader为我们提供了对Dataset的读取操作，常用参数有：batch_size(每个batch的大小)、 shuffle(是否进行shuffle操作)、 num_workers(加载数据的时候使用几个子进程)。下面做一个简单的操作</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">ds_demo</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">idata</span><span class="o">=</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">idata</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([</span><span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span>
        <span class="mf">24000.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<p>常见的用法是使用for循环对其进行遍历</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dl</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># 为了节约空间，这里只循环一遍</span>
    <span class="k">break</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span> <span class="mf">24000.</span><span class="p">,</span>
        <span class="mf">24000.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<p>我们已经可以通过dataset定义数据集，并使用Datalorder载入和遍历数据集，除了这些以外，PyTorch还提供能torcvision的计算机视觉扩展包，里面封装了</p>
</section>
<section id="torchvision">
<h2><span class="section-number">3.1.15.3. </span>torchvision 包<a class="headerlink" href="#torchvision" title="Permalink to this heading"></a></h2>
<p>torchvision 是PyTorch中专门用来处理图像的库，PyTorch官网的安装教程中最后的pip install torchvision 就是安装这个包。</p>
<section id="torchvision-datasets">
<h3><span class="section-number">3.1.15.3.1. </span>torchvision.datasets<a class="headerlink" href="#torchvision-datasets" title="Permalink to this heading"></a></h3>
<p>torchvision.datasets 可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多的图片数据集，我们拿来就可以直接使用：</p>
<ul class="simple">
<li><p>MNIST</p></li>
<li><p>COCO</p></li>
<li><p>Captions</p></li>
<li><p>Detection</p></li>
<li><p>LSUN</p></li>
<li><p>ImageFolder</p></li>
<li><p>Imagenet-12</p></li>
<li><p>CIFAR</p></li>
<li><p>STL10</p></li>
<li><p>SVHN</p></li>
<li><p>PhotoTour
我们可以直接使用，示例如下：</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="c1"># 表示 MNIST 数据的加载的目录</span>
                                      <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 表示是否加载数据库的训练集，false的时候加载测试集</span>
                                      <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># 表示是否自动下载 MNIST 数据集</span>
                                      <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># 表示是否需要对数据进行预处理，none为不进行预处理</span>
</pre></div>
</div>
</section>
<section id="torchvision-models">
<h3><span class="section-number">3.1.15.3.2. </span>torchvision.models<a class="headerlink" href="#torchvision-models" title="Permalink to this heading"></a></h3>
<p>torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习
torchvision.models模块的 子模块中包含以下模型结构。</p>
<ul class="simple">
<li><p>AlexNet</p></li>
<li><p>VGG</p></li>
<li><p>ResNet</p></li>
<li><p>SqueezeNet</p></li>
<li><p>DenseNet</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#我们直接可以使用训练好的模型，当然这个与datasets相同，都是需要从服务器下载的</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="torchvision-transforms">
<h3><span class="section-number">3.1.15.3.3. </span>torchvision.transforms<a class="headerlink" href="#torchvision-transforms" title="Permalink to this heading"></a></h3>
<p>transforms 模块提供了一般的图像转换操作类，用作数据处理和数据增强</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1">#先四周填充0，在把图像随机裁剪成32*32</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>  <span class="c1">#图像一半的概率翻转，一半的概率不翻转</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">((</span><span class="o">-</span><span class="mi">45</span><span class="p">,</span><span class="mi">45</span><span class="p">)),</span> <span class="c1">#随机旋转</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)),</span> <span class="c1">#R,G,B每层的归一化用到的均值和方差</span>
<span class="p">])</span>
</pre></div>
</div>
<p>肯定有人会问：(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) 这几个数字是什么意思？</p>
<p>官方的这个帖子有详细的说明:
https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21
这些都是根据ImageNet训练的归一化参数，可以直接使用，我们认为这个是固定值就可以</p>
<p>我们已经完成了Python的基本内容的介绍，下面我们要介绍神经网络的理论基础，里面的公式等内容我们都使用PyTorch来实现</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="2.1.3-pytorch-basics-nerual-network.html" class="btn btn-neutral float-left" title="3.1.14. PyTorch 基础 : 神经网络包nn和优化器optm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="2.2-deep-learning-basic-mathematics.html" class="btn btn-neutral float-right" title="3.1.16. 2.2 深度学习基础及数学原理" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2024.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
  
<div class="view_counter">
      <img class="img_view_counter" src="https://s01.flagcounter.com/count2/m02K/bg_FFFFFF/txt_F77B1B/border_CCCCCC/columns_3/maxflags_6/viewers_3/labels_1/pageviews_0/flags_0/percent_0/" alt="View Counter" border="0" />
</div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="版本">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Read the Docs</span>
        v: latest
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>版本</dt>
            <dd><a href="#">latest</a></dd>
        </dl>
    </div>
</div>

</body>
</html>